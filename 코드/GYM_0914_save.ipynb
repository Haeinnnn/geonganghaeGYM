{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZEw4XqL4VuD"
      },
      "source": [
        "#드라이브 바운드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eS2Xp_QB03PO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19300329-8329-489a-90df-817b49556664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2_S78dA208M"
      },
      "source": [
        "#DATA 작 해주기 - train/test/validation\n",
        "\n",
        "\n",
        "```\n",
        "1. split folder ratio 사용\n",
        "!pip install split-folders\n",
        "import splitfolders\n",
        "\n",
        "#splitfolders.ratio('인풋경로',output='output경로' ,seed=77, ratio= (0.8,0.1,0.1)) \n",
        "#처음폴더를 output foloder(없다면 생성해준후 실행)로 train-valid-test 데이터를 0.8,0.1,0.1의 비율로 나눠줘\n",
        "\n",
        "# splitfolders.ratio('/content/drive/MyDrive/tmp/pose_estimiation/bad',)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaYhZPZkVWgC"
      },
      "source": [
        "#YOLO를 인식"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV8SMXRAVaMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19916f0c-d7fa-4ade-ed3f-0feb5c6649f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efHIM12lVg3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f76a0377-00a0-4ce9-bbb1-6fd65fa32943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'darkeras-yolov4'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 175 (delta 27), reused 25 (delta 23), pack-reused 139\u001b[K\n",
            "Receiving objects: 100% (175/175), 8.08 MiB | 14.16 MiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dhrim/darkeras-yolov4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L12zKlHSVn4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "570e73a4-5e7c-4211-cb35-e6f59fb7fd68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darkeras-yolov4\n"
          ]
        }
      ],
      "source": [
        "%cd darkeras-yolov4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVKmdV4ZVpJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d0d0c0d-8127-4d13-fc3b-988e71a39394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-09 02:17:39--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘weights/yolov3.weights’\n",
            "\n",
            "weights/yolov3.weig 100%[===================>] 236.52M  22.9MB/s    in 11s     \n",
            "\n",
            "2022-09-09 02:17:50 (21.5 MB/s) - ‘weights/yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O weights/yolov3.weights https://pjreddie.com/media/files/yolov3.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOyW9uBoVslB"
      },
      "source": [
        "##모델 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCi3HPGCVvjp"
      },
      "outputs": [],
      "source": [
        "import yolov3_wrapper\n",
        "model = yolov3_wrapper.YoloV3Wrapper(\"weights/yolov3.weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9R_Dq1T9VxKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58befc0f-1ffe-47a1-81b3-a325824a3b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "model.save(\"yolov3.h5\")#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4Kd-_pIZEV_"
      },
      "source": [
        "##이미지 로딩 \n",
        "- 이는 sit, stand를 따로 진행한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAA1H2UTY6u4"
      },
      "outputs": [],
      "source": [
        "#폴더의 모든 사진을 불러옴 - 확인용 코드(안돌려도 됨)\n",
        "import glob\n",
        "\n",
        "for filename in glob.glob('/gdrive/MyDrive/PROJECT/DATA0829/SIT1500/*/*.jpg'):\n",
        "  #print(filename)\n",
        "  name_list = filename.split(\"/\")\n",
        "  #print(name_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqXVYM0QVO3-"
      },
      "source": [
        "#OpenPose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWhIwqKGZVFs"
      },
      "source": [
        "##프로젝트 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYPOtsCtZUkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dedd605d-eb86-49d4-a017-b922aa910c16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTQ8-mkkVOLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d44a00b8-9fae-4b31-90e1-df2e635acc6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Open-Pose-Keras'...\n",
            "remote: Enumerating objects: 418, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 418 (delta 11), reused 21 (delta 11), pack-reused 397\u001b[K\n",
            "Receiving objects: 100% (418/418), 29.70 MiB | 20.66 MiB/s, done.\n",
            "Resolving deltas: 100% (236/236), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dhrim/Open-Pose-Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cMtaCm2ZfSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365970c7-cc9b-4eee-9996-9d27672bd3d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Open-Pose-Keras\n"
          ]
        }
      ],
      "source": [
        "%cd Open-Pose-Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqWJXqgyZigN"
      },
      "source": [
        "##install library & 모델 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJnm6I4DZlv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43166ce-a135-4e42-8b79-c269a1a0366f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting configobj\n",
            "  Downloading configobj-5.0.6.tar.gz (33 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from configobj) (1.15.0)\n",
            "Building wheels for collected packages: configobj\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-py3-none-any.whl size=34547 sha256=f6b9718348a5572089b5856e590a72ef66ee7dd2c7386a3572f0eb5582bbe6dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/c4/19/13d74440f2a571841db6b6e0a273694327498884dafb9cf978\n",
            "Successfully built configobj\n",
            "Installing collected packages: configobj\n",
            "Successfully installed configobj-5.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install configobj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st6wlaQYZu3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e843ba4-7ac0-4903-dc68-7e9a30db21fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1d9HGnnLhq6IhC5ZSVpBf7bSrpjNj5kPB\n",
            "To: /content/Open-Pose-Keras/open_pose_model.h5\n",
            "100%|██████████| 210M/210M [00:02<00:00, 74.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "from open_pose_wrapper import OpenPoseWrapper\n",
        "model = OpenPoseWrapper()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaDReQqzZ1Go"
      },
      "source": [
        "##pose detect\n",
        "- https://cmu-perceptual-computing-lab.github.io/openpose/web/html/doc/md_doc_03_python_api.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQnEzvEejIhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00cde4f-e3d8-4d69-d7da-ae61339b5070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Open-Pose-Keras\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Open-Pose-Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdUa0_w5fB-D"
      },
      "source": [
        "from open_pose_wrapper import OpenPoseWrapper\n",
        "이 부분을 시행 해주어야 error안난다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL39xKGrO5Bk"
      },
      "source": [
        "#Get angle  vlaue\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMnfvcyqE5sg"
      },
      "source": [
        "##Get angle  vlaue_save.csv (09/09)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-mKFU0eZKQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be1e07d-7b2e-42d7-9cd7-82478247ec00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /gdrive/MyDrive/PROJECT/DATA0829/tmp_data/sit_0908.csv\n"
          ]
        }
      ],
      "source": [
        "#9/9\n",
        "# /gdrive/MyDrive/PROJECT/DATA0829/tmp_data/stand_0908.csv\n",
        "# FILE_Name,Neck,Hip,OuPut\n",
        "\n",
        "%%writefile /gdrive/MyDrive/PROJECT/DATA0829/tmp_data/sit_0908.csv\n",
        "FILE_Name,Neck,Knee,OuPut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QfwxujzbY6r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "7368239f-abb2-42b3-b4aa-806f7eca17d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [FILE_Name, Neck, Knee, OuPut]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ff6d8dd-b2c4-42cb-8d40-7eb33e75a8b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FILE_Name</th>\n",
              "      <th>Neck</th>\n",
              "      <th>Knee</th>\n",
              "      <th>OuPut</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ff6d8dd-b2c4-42cb-8d40-7eb33e75a8b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ff6d8dd-b2c4-42cb-8d40-7eb33e75a8b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ff6d8dd-b2c4-42cb-8d40-7eb33e75a8b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "cv_ad='/gdrive/MyDrive/PROJECT/DATA0829/tmp_data/sit_0908.csv'\n",
        "tmp_dict=pd.read_csv (cv_ad, encoding=\"euc-kr\") \n",
        "tmp_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV5gSuc1ZgvB"
      },
      "source": [
        "```\n",
        "https://www.geeksforgeeks.org/how-to-append-pandas-dataframe-to-existing-csv-file/\n",
        "``` --> we can write the dataframe to the CSV file in append mode by the parameter a using the pandas to_csv() function.\n",
        "적용은 작업완료후 되는듯?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-XWVfYmxLWJ"
      },
      "source": [
        "추출된 점이 담긴 all_peaks는 18개의 요소가 있는 리스트이다.\n",
        "- part_str[#] :신체부위 text\n",
        "- all_peaks[1#][2#][3#] :\n",
        "    - [1#] : the people tuple data to list // 즉 한 신체부위의 값이다. 다수의 사람에 대해\n",
        "```\n",
        "(484, 130, 0.7376982569694519, 1)\n",
        "  x    y   score               point_id\n",
        "```\n",
        "    - [2#] : one person data\n",
        "    - [3#] : 한 사람의 데이터에서 특정 데이터 추출\n",
        "- 18 parts\n",
        "```\n",
        "part_str = [nose, neck, Rsho, Relb, Rwri, Lsho, Lelb, Lwri, Rhip, Rkne, Rank, Lhip, Lkne, Lank, Leye, Reye, Lear, Rear, pt19]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf9xBOQKamfi"
      },
      "source": [
        "##train sit에 대해서만(전반적으로 이용가능하게 수정 필요./반복을 가능한 줄이자)\n",
        "- 저장하는 부분\n",
        "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1mcvAYCFH_E"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import config_reader\n",
        "import math\n",
        "from IPython.display import Image, display\n",
        "from google.colab import output\n",
        "\n",
        "#directory address\n",
        "dad='/gdrive/MyDrive/PROJECT/DATA0829/SIT1500/TRAIN/*/*.jpg'\n",
        "excp_list=[]#예외처리된 파일 이름 저장\n",
        "#/gdrive/MyDrive/PROJECT/DATA0829/STAND1500/TRAIN/BAD1\n",
        "for file_name in glob.glob(dad): #원하는 디렉토리 경로로 변경\n",
        "  all_peaks,subset,candidate = model.extract(file_name)\n",
        "  model.draw_result(file_name, all_peaks, subset, candidate, draw_dot=True, draw_line=True)#\n",
        "  print(\"FILE_NAME\",file_name)\n",
        "  #get data feacture - split text -> pos,state,fname \n",
        "  d=file_name.split(\"/\")#return list\n",
        "  # print(d)\n",
        "  pos=d[d.index(\"DATA0829\")+1].strip(\"1500\")\n",
        "  st=d[d.index(\"DATA0829\")+3]\n",
        "  fn=d[d.index(\"DATA0829\")+4]\n",
        "  # print(\"pos:\",pos,\"state:\",st,\"name:\",fn)\n",
        "\n",
        "  #3\n",
        "  #part_str = [nose, neck, Rsho, Relb, Rwri, Lsho, Lelb, Lwri, Rhip, Rkne, Rank, Lhip, Lkne, Lank, Leye, Reye, Lear, Rear, pt19]\n",
        "  _, model_params = config_reader.config_reader()\n",
        "  part_str = model_params['part_str']\n",
        "\n",
        "  #4\n",
        "  #Relb가 없으면 왼쪽을 바라 본 사진임으로 Relb 유무로 사진의 좌우를 판별\n",
        "    #에러 처리\n",
        "  try:\n",
        "    if not all_peaks[3]: #Relb가 없는 경우 - 왼쪽을 바라본 사진\n",
        "      if not all_peaks[-2]:\n",
        "        all_peaks[-2] = all_peaks[-1]\n",
        "    #atan2(y, x) \n",
        "      neck_angle = math.degrees(math.atan2(all_peaks[5][0][1] - all_peaks[-2][0][1], all_peaks[5][0][0] - all_peaks[-2][0][0])) #어깨 - 귀\n",
        "      spine_angle = math.degrees(math.atan2(all_peaks[12][0][1] - all_peaks[11][0][1], all_peaks[12][0][0] - all_peaks[11][0][0])) #무릎 - 엉덩이\n",
        "      \n",
        "      sx,sy=all_peaks[5][0][0],all_peaks[5][0][1]\n",
        "      ex,ey= all_peaks[-2][0][0], all_peaks[-2][0][1]\n",
        "      kx,ky=all_peaks[12][0][0],all_peaks[12][0][1]\n",
        "      bx,by= all_peaks[11][0][0], all_peaks[11][0][1]\n",
        "    else: \n",
        "      if not all_peaks[-1]:\n",
        "        all_peaks[-1] = all_peaks[-2]\n",
        "      neck_angle = abs(math.degrees(math.atan2(all_peaks[-1][0][1] - all_peaks[2][0][1], all_peaks[-1][0][0] - all_peaks[2][0][0]))) #귀 - 어깨\n",
        "      spine_angle = math.degrees(math.atan2(all_peaks[9][0][1] - all_peaks[8][0][1], all_peaks[9][0][0] - all_peaks[8][0][0]))\n",
        "      \n",
        "      sx,sy= all_peaks[2][0][0], all_peaks[2][0][1]\n",
        "      ex,ey=all_peaks[-1][0][0],all_peaks[-1][0][1]\n",
        "      kx,ky= all_peaks[8][0][0], all_peaks[8][0][1]\n",
        "      bx,by= all_peaks[9][0][0], all_peaks[9][0][1]\n",
        "    #print(f\"angle: neck_angle = {neck_angle}, spine_angle = {spine_angle}\")\n",
        "  except IndexError:\n",
        "    excp_list.append(fn)S\n",
        "    continue\n",
        "  sxy=(sx,sy)\n",
        "  exy=(ex,ey)\n",
        "  kxy=(kx,ky)\n",
        "  bxy=(bx,by)\n",
        "  #4-1 90degree over 예외처리?맞는지 확인 필요(09/05)\n",
        "  if neck_angle>90:\n",
        "    neck_angle=neck_angle-90\n",
        "  elif spine_angle>180:\n",
        "    spine_angle=spine_angle-180\n",
        "  #5\n",
        "  neck_angle = round(neck_angle ,3)#소숫점 3 자리까지2\n",
        "  spine_angle = round(spine_angle,3)\n",
        "\n",
        "  #6-2\n",
        "  #stand_FILE_Name,Neck,Hip,OuPut\n",
        "  dt={\"FILE_Name\":[fn],\"Neck\":[str(neck_angle)],\"Knee\":[str(spine_angle)],\"OuPut\":[st]}\n",
        "  #sit\n",
        "    #dt={\"FILE_Name\":[fn],\"Neck\":[str(neck_angle)],\"Knee\":[str(spine_angle)],\"OuPut\":[st]}\n",
        "  tmp_dict=pd.DataFrame(dt)\n",
        "  tmp_dict.to_csv(cv_ad,mode='a',index=False,header=False)\n",
        "  print(\"tmp_dict: \",tmp_dict)\n",
        "print(\"예외처리된 파일 이름\",excp_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t87zcE6rbGFZ"
      },
      "source": [
        "##파일 출력하는 기능[csv]\n",
        "- tmp (9/6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxzMaY3ZbNXi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "#directory address\n",
        "#dad='/gdrive/MyDrive/PROJECT/DATA0829/SIT1500/TRAIN/*/*.jpg'\n",
        "\n",
        "for file_name in glob.glob(cv_ad):\n",
        "  with open(file_name, newline='', encoding='utf-8') as f:\n",
        "      reader = csv.reader(f)#to_csv로 바꾸기\n",
        "      for row in reader:\n",
        "          print(row)#저장을 해야할까 바로 불러서 쓰는 방식을 이용해야 하는지 고민해야 할것 같다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnlQEnFRqhAK"
      },
      "source": [
        "##all peaks print / 확인용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2fZI0pEaNV6"
      },
      "outputs": [],
      "source": [
        "import config_reader\n",
        "\n",
        "_, model_params = config_reader.config_reader()\n",
        "part_str = model_params['part_str']\n",
        "for i in range(18):\n",
        "  print(part_str[i], \": \", all_peaks[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cVDjeCEaWqA"
      },
      "outputs": [],
      "source": [
        "#기존 예시 코드 - 실행 x\n",
        "model.extract_and_draw(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4t3V9SEaeSE"
      },
      "outputs": [],
      "source": [
        "print(len(all_peaks))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdOGxMg7aan7"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# 코드로 형식 지정됨\n",
        "```\n",
        "\n",
        "###all peaks print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boygmKC6agUA"
      },
      "outputs": [],
      "source": [
        "import config_reader\n",
        "\n",
        "_, model_params = config_reader.config_reader()\n",
        "part_str = model_params['part_str']\n",
        "for i in range(18):\n",
        "  print(part_str[i], \": \", all_peaks[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiv9ZYIbakk9"
      },
      "source": [
        "\n",
        "- 1개의 point는 다음과 같이 구성된다.\n",
        "```\n",
        "(484, 130, 0.7376982569694519, 1)\n",
        "  x    y   score               point_id\n",
        "```\n",
        "- point_id는 all_peaks에 명시되어 있다.\n",
        "\n",
        "```\n",
        "all_peaks의 내용\n",
        "\n",
        "(177, 6, 0.11634597013471648, 0)\n",
        "(484, 130, 0.7376982569694519, 1)\n",
        "(287, 154, 0.9168482273817062, 2)\n",
        "(410, 221, 0.9359188675880432, 3)\n",
        "\n",
        "각 줄의 마지막 숫자가 point_id이다.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joTx4Cnbam3s"
      },
      "source": [
        "subset의 경우 이미지에서 한 사람의 값을 가진다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJRv80HEa65I"
      },
      "source": [
        "각 포인트별 연결 가능 여부는 limSeq에 담겨 있다.\n",
        "\n",
        "\n",
        "\n",
        "[2, 3] 은 neck과 Rsho(righst shoulder)가 연결되어 있음을 의미하고, \n",
        "\n",
        "[3,4]는 Rsho(righst shoulder)와 Relb(right elbow)가 이어져 있다는 것을 의미한다.\n",
        "\n",
        "```\n",
        "1: nose\n",
        "2: neck\n",
        "3: Rsho\n",
        "4: Relb\n",
        "5: Rwri\n",
        "...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtChU3CVO9c6"
      },
      "source": [
        "#Save&Load .csv file data\n",
        "\n",
        "\n",
        "```\n",
        "x, y, NA, SA, class1, class2\n",
        "\n",
        "```\n",
        "- if the vlaue not exist- > 0 or None\n",
        "-  참고자료 \n",
        "https://colab.research.google.com/github/datascienceschool/book/blob/master/ds/01%20python/04.02%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%9E%85%EC%B6%9C%EB%A0%A5.ipynb#scrollTo=ZQxwXT9GP-4A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyrJ8t0VQ9_E"
      },
      "source": [
        "`%%writefile` 매직(magic) 명령으로 만들어보자. 이 명령은 셀에 서술한 내용대로 텍스트 파일을 만드는 명령이다.\n",
        "```\n",
        "%%writefile STAND_TRAIN.csv\n",
        "x, y, NA, SA, class1, class2\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJFRG75MRVvP"
      },
      "source": [
        "## CSV파일로부터 데이터를 읽어 데이터 프레임을 만들 때\n",
        "- CSV 파일로부터 데이터를 읽어 데이터프레임을 만들 때는 `pandas.read_csv` 함수를 사용한다. 함수의 입력값으로 파일 이름을 넣는다.\n",
        "- 확장자가 CSV가 아닌 파일 즉, 데이터를 구분하는 구분자(separator)가 쉼표(comma)가 아니면 `sep` 인수를 써서 구분자를 사용자가 지정해준다. 만약 길이가 정해지지 않은 공백이 구분자인 경우에는 `\\s+` 정규식(regular expression) 문자열을 사용한다.\n",
        "- 만약 자료 파일 중에 건너 뛰어야 할 행이 있으면 ```skiprows ```인수를 read_csv함수에 적용하여 이용\n",
        "- 특정한 값을 NaN으로 취급하고 싶으면 `na_values` 인수에 NaN 값으로 취급할 값을 넣는다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnXqPLlsRJyj"
      },
      "outputs": [],
      "source": [
        "pd.read_csv('STAND_TRAIN.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlPHb-aJT_KD"
      },
      "outputs": [],
      "source": [
        "#pd.read_table('STAND_TRAIN.txt', sep='\\s+')#pd.read_csv('sample4.txt', skiprows=[0, 1])\n",
        "#df = pd.read_csv('sample5.csv', na_values=['누락'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA8JXLycUnB-"
      },
      "source": [
        "##CSV파일 출력\n",
        "- `to_csv` 메서드를 사용한다.(cat과 비슷하게 인자를 추가해서 이용이 가능)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icPgphWcyd2u"
      },
      "source": [
        "#Vanilla CNN Template\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3g9RX2BS7oV"
      },
      "source": [
        "##모듈임포팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PjQAtOCyco0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import GaussianNoise\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, BatchNormalization, Conv2D, MaxPooling2D, Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "import time\n",
        "\n",
        "from tensorflow.keras.applications import efficientnet\n",
        "from tensorflow.keras.applications import EfficientNetB2\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcX4sUfDS4o9"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Input((224,224,3)))\n",
        "model.add(GaussianNoise(0.1))\n",
        "model.add(Conv2D(64, (3,3), padding='same'))\n",
        "model.add(Conv2D(64, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(128, (3,3), padding='same'))\n",
        "model.add(Conv2D(128, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(256, (3,3), padding='same'))\n",
        "model.add(Conv2D(256, (3,3), padding='same'))\n",
        "model.add(Conv2D(256, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq3wSN5LwWth"
      },
      "outputs": [],
      "source": [
        "#다중분류\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"Adam\", metrics=['acc'])\n",
        "#good,bad만 분류하면되니까 2진분류\n",
        "# model.compile(loss='binary_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "def normalize(image):\n",
        "  return image/255.0\n",
        "\n",
        "preprocessor = normalize\n",
        "BATCH_SIZE = 64 # BATCH_SIZE = 128\n",
        "\n",
        "train_data_generator = ImageDataGenerator(#이미지 augmentation(증가) / return v - 입력이 변형된 상태\n",
        "      rotation_range=5, #bad1~4,good 5개\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=False,\n",
        "      preprocessing_function=preprocessor\n",
        ").flow_from_directory(#이미지가 저장된 폴더를 기준으로 라벨 정보와 함께 이미지를 불러들임\n",
        "      \"/gdrive/MyDrive/PROJECT/DATA0829/STAND1500/TRAIN\",#학습시킬 경로\n",
        "      target_size=(224,224),#이미지 크기 fix - 넘어가게 되면 그래픽 에러 남\n",
        "      batch_size=BATCH_SIZE,\n",
        "      class_mode='sparse'\n",
        ")\n",
        "\n",
        "test_data_generator = ImageDataGenerator(\n",
        "      preprocessing_function=preprocessor#이미지 처리전에 주어진 값을곱해 크기를 조정.    \n",
        ").flow_from_directory(\n",
        "      \"/gdrive/MyDrive/PROJECT/DATA0829/STAND1500/TEST\", #test경로\n",
        "      target_size=(224,224),\n",
        "      batch_size=BATCH_SIZE,\n",
        "      class_mode='sparse'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHDruxJ7wwwC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "model_check_point = ModelCheckpoint(\n",
        "    'pose_best_model.h5', \n",
        "    monitor='val_loss', \n",
        "    verbose=1, \n",
        "    save_best_only=True)\n",
        "#모델체크포인트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TIWmkkG27Vz"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "      train_data_generator,\n",
        "      validation_data=test_data_generator,\n",
        "      steps_per_epoch=train_data_generator.samples/BATCH_SIZE,\n",
        "      validation_steps=test_data_generator.samples/BATCH_SIZE,      \n",
        "      epochs=100, callbacks=[model_check_point]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKcUQN2KSsEp"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('pose_best_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIvMXsI6bUz-"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(\n",
        "      test_data_generator,\n",
        "      steps=test_data_generator.samples/BATCH_SIZE\n",
        ")\n",
        "print(\"loss=\", loss)\n",
        "print(\"acc=\", acc)\n",
        "\n",
        "\n",
        "\n",
        "test_x, test_y = next(iter(test_data_generator))\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=-1)\n",
        "\n",
        "plt.plot(test_y[:100], \"o\")\n",
        "plt.plot(predicted[:100], '.')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7d9neMj38kA"
      },
      "source": [
        "https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/tutorials/keras/save_and_load.ipynb?hl=ko\n",
        "\n",
        "참고 사이트"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}