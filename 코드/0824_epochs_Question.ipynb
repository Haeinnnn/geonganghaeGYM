{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0824_epochs_Question.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TM2skNpUILpD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vanilla CNN Template"
      ],
      "metadata": {
        "id": "vgUsDlxLIOha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, BatchNormalization, Conv2D, MaxPooling2D, Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications import efficientnet\n",
        "from tensorflow.keras.applications import EfficientNetB2\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(Input((224,224,3)))\n",
        "model.add(Conv2D(64, (3,3), padding='same'))\n",
        "model.add(Conv2D(64, (3,3), padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(128, (3,3), padding='same'))\n",
        "model.add(Conv2D(128, (3,3), padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(256, (3,3), padding='same'))\n",
        "model.add(Conv2D(256, (3,3), padding='same'))\n",
        "model.add(Conv2D(256, (3,3), padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(5, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "_1OX5Q8AIN7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#다중분류\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])\n",
        "#good,bad만 분류하면되니까 2진분류\n",
        "# model.compile(loss='binary_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "def normalize(image):\n",
        "  return image/255.0\n",
        "\n",
        "preprocessor = normalize\n",
        "# BATCH_SIZE = 32\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_data_generator = ImageDataGenerator(\n",
        "      # rotation_range=10,\n",
        "      rotation_range=5, #bad1~4,good 5개\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=False,\n",
        "      preprocessing_function=preprocessor\n",
        ").flow_from_directory(\n",
        "      \"/content/drive/MyDrive/DATA/STAND/TRAIN\",#학습시킬 경로\n",
        "      target_size=(224,224),\n",
        "      batch_size=BATCH_SIZE,\n",
        "      class_mode='sparse'\n",
        ")\n",
        "\n",
        "test_data_generator = ImageDataGenerator(\n",
        "      preprocessing_function=preprocessor\n",
        ").flow_from_directory(\n",
        "      \"/content/drive/MyDrive/DATA/STAND/TEST\", #test경로\n",
        "      target_size=(224,224),\n",
        "      batch_size=BATCH_SIZE,\n",
        "      class_mode='sparse'\n",
        ")\n"
      ],
      "metadata": {
        "id": "f5o1WFkHIRaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "model_check_point = ModelCheckpoint(\n",
        "    'pose_best_model.h5', \n",
        "    monitor='val_loss', \n",
        "    verbose=1, \n",
        "    save_best_only=True)\n",
        "#모델체크포인트"
      ],
      "metadata": {
        "id": "_bbT0PK_ITeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "      train_data_generator,\n",
        "      validation_data=test_data_generator,\n",
        "      steps_per_epoch=train_data_generator.samples/BATCH_SIZE,\n",
        "      validation_steps=test_data_generator.samples/BATCH_SIZE,      \n",
        "      epochs=5, callbacks=[model_check_point]\n",
        ")\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(\n",
        "      test_data_generator,\n",
        "      steps=test_data_generator.samples/BATCH_SIZE\n",
        ")\n",
        "print(\"loss=\", loss)\n",
        "print(\"acc=\", acc)\n",
        "\n",
        "\n",
        "\n",
        "test_x, test_y = next(iter(test_data_generator))\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=-1)\n",
        "\n",
        "plt.plot(test_y[:100], \"o\")\n",
        "plt.plot(predicted[:100], '.')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8DYTJ5RxIWoG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}