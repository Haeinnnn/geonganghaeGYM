{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU-2SbZjRXzF"
      },
      "source": [
        "#YOLO를 인식"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Qrk3AQqRkUl",
        "outputId": "faf6f102-ea68-4ba0-d7dc-df91843aaadb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'darkeras-yolov4'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 175 (delta 27), reused 25 (delta 23), pack-reused 139\u001b[K\n",
            "Receiving objects: 100% (175/175), 8.08 MiB | 2.61 MiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dhrim/darkeras-yolov4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtSP683BWABO",
        "outputId": "d7806a92-670b-41b4-994b-6a8aa049b0e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darkeras-yolov4/darkeras-yolov4/darkeras-yolov4\n"
          ]
        }
      ],
      "source": [
        "%cd darkeras-yolov4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs1-TPGtSCpX",
        "outputId": "c8304668-f7bf-4482-c737-e88da758e908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-26 19:40:33--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘weights/yolov3.weights’\n",
            "\n",
            "weights/yolov3.weig 100%[===================>] 236.52M  20.9MB/s    in 12s     \n",
            "\n",
            "2022-08-26 19:40:46 (19.3 MB/s) - ‘weights/yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O weights/yolov3.weights https://pjreddie.com/media/files/yolov3.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpPC8WVIR0JB"
      },
      "source": [
        "##모델 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "q2V7OXyeR7Mk"
      },
      "outputs": [],
      "source": [
        "import yolov3_wrapper\n",
        "model = yolov3_wrapper.YoloV3Wrapper(\"weights/yolov3.weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzaMufllgEUd",
        "outputId": "80569e22-dadf-4213-e23d-bc74170ff1fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "model.save(\"yolov3.h5\")#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juErSJooOdmB"
      },
      "source": [
        "#구글 드라이브 마운트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evz4FpSqOfsP",
        "outputId": "63678b28-dd0d-4bab-903a-65f019fdfd28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL5CF0VZicIy"
      },
      "source": [
        "##이미지 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wj4Vg_bLQWj6"
      },
      "outputs": [],
      "source": [
        "#폴더의 모든 사진을 불러옴 - 확인용 코드(안돌려도 됨)\n",
        "import glob\n",
        "\n",
        "for filename in glob.glob('/gdrive/MyDrive/DATA/5/good/2/*.jpg'):\n",
        "  print(filename)\n",
        "  name_list = filename.split(\"/\")\n",
        "  print(name_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHIfjMuxRM3l"
      },
      "source": [
        "#필요 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "EcH5yOdVROGj"
      },
      "outputs": [],
      "source": [
        "import core\n",
        "import colorsys\n",
        "import random\n",
        "\n",
        "def draw_bbox(file_name1, bboxes, show_label=True):\n",
        "    \"\"\"\n",
        "    bboxes: [x_min, y_min, x_max, y_max, probability, cls_id] format coordinates.\n",
        "    \"\"\"\n",
        "    Msc=[0]\n",
        "    #classes : 딕셔너리 가능 항목 가져옴 num:str\n",
        "    try:\n",
        "        classes = class_names\n",
        "    except NameError:\n",
        "        classes = core.utils.read_class_names(\"./data/classes/coco.names\")\n",
        "    num_classes = len(classes)\n",
        "    image_h, image_w, _ = file_name1.shape#이미지 크기\n",
        "\n",
        "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
        "\n",
        "    random.seed(0)\n",
        "    random.shuffle(colors)\n",
        "    random.seed(None)\n",
        "\n",
        "    for i, bbox in enumerate(bboxes):#indexing(count, list v)\n",
        "        coor = np.array(bbox[:4], dtype=np.int32)\n",
        "        \n",
        "        fontScale = 0.5\n",
        "        score = bbox[4]\n",
        "        Msc=np.append(Msc,score)\n",
        "        class_ind = int(bbox[5])\n",
        "     \n",
        "        print(\"BOL\",classes[class_ind])\n",
        "        if classes[class_ind] in \"person\" :\n",
        "          if score>=np.max(Msc):\n",
        "            bbox_color = colors[class_ind]\n",
        "            bbox_thick = int(0.6 * (image_h + image_w) / 600)\n",
        "            c1, c2 = (coor[0], coor[1]), (coor[2], coor[3]) \n",
        "            cv2.rectangle(file_name1, c1, c2, bbox_color, bbox_thick)\n",
        "            score=np.max(Msc)\n",
        "            print('%s'%classes[class_ind],\"SC\",score)\n",
        "            bbox_mess = '%s: %.2f' % (classes[class_ind], score)#출력되는 text\n",
        "            t_size = cv2.getTextSize(bbox_mess, 0, fontScale, thickness=bbox_thick//2)[0]\n",
        "            cv2.rectangle(file_name1, c1, (c1[0] + t_size[0], c1[1] - t_size[1] - 3), bbox_color, -1)  # filled#labeling2\n",
        "            #이미지 파일,시작점(x,y),종료점(x,y)\n",
        "\n",
        "            c1_1= (c1[0] + t_size[0], c1[1] - t_size[1] - 3)\n",
        "            #이미지 추출은 y:y+h, x:x+w로 주어준다.\n",
        "\n",
        "            ####PP=file_name1[c1[1]:c1_1[1],c1[0]:c1_1[0]]#+x값>,-y값(위 아래)<#y맞음\n",
        "            #print(\"x/y\",c1_1[1]-c1[1],\"/\",c1[0]-c1_1[0])#높이, 너비 -\n",
        "            PP=file_name1[c1[1]:c2[1],c1[0]:c2[0]]\n",
        "\n",
        "            PP = cv2.cvtColor(PP, cv2.COLOR_RGB2BGR) # 색상 변경\n",
        "            cv2.imwrite(\"/gdrive/MyDrive/tmp/good/\" + name_list[len(name_list) - 1], PP)# 사람 부분만 이미지 추출 #자기의 tmp 폴더에 good 폴더 미리 생성\n",
        "            ####print(c1[0],c1_1[0],\"//\",c1[1],c1_1[1])#376 476 // 0 -13\n",
        "            \n",
        "            cv2.putText(file_name1, bbox_mess, (c1[0], c1[1]-2), cv2.FONT_HERSHEY_SIMPLEX,fontScale, (0, 0, 0), bbox_thick//2, lineType=cv2.LINE_AA)#labeling2\n",
        "    #print(\"Msc\",Msc,\"//\",max(Msc)) #Msc [0.98066556 0.9436748  0.41189495 0.26212615] // 0.9806655645370483\n",
        "\n",
        "    return file_name1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EP86kZaWEEQ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import core\n",
        "import colorsys\n",
        "import random\n",
        "\n",
        "for filename in glob.glob('/gdrive/MyDrive/DATA/5/good/2/*.jpg'):  # \"DATA/5/good/2/\"의 모든 사진들을 불러옴\n",
        "  print(filename)\n",
        "  name_list = filename.split(\"/\")\n",
        "  new_filename = \"/gdrive/MyDrive/DATA/5/good/2/\" + name_list[len(name_list) - 1] # 사진 파일 이름을 new_filename에 저장\n",
        "  INPUT_SIZE = 800\n",
        "\n",
        "  image_path = filename\n",
        "  file_name = cv2.imread(image_path)#이미지 파일 경로\n",
        "  file_name = cv2.cvtColor(file_name, cv2.COLOR_BGR2RGB)#입력 이미지,색상 변환 코드\n",
        "\n",
        "  plt.figure(figsize=(12,20))\n",
        "  plt.imshow(file_name)\n",
        "  plt.show()\n",
        "\n",
        "  #2\n",
        "  bboxes = model.predict(file_name)#keras코드에서 boundary box로 bounding 됨\n",
        "\n",
        "  #3\n",
        "  dummy = np.copy(file_name)\n",
        "\n",
        "  for box in bboxes:\n",
        "    x1, y1, x2, y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
        "    conf = box[4]\n",
        "    cls_id = int(box[5])\n",
        "    dummy = cv2.rectangle(dummy, (x1,y1), (x2,y2), (255,0,0), 2)#빨간색, 선의 두께는 2\n",
        "\n",
        "  plt.figure(figsize=(12,20))#(그래프 가로, 세로)\n",
        "  plt.gca().set_title(\"yolov3\") # get current figure 현재의 figure를 확인하기 위한 방법 /입력한 제목 추가 \n",
        "  #Axes반환한다(실제 이미지데이터의 역할)\n",
        "  plt.imshow(dummy)#원하는 사이즈의 픽셀을 원하는 색으로 채워서 만든 그림 \n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  #4\n",
        "  file_name = draw_bbox(file_name, bboxes)\n",
        "  #plt.figure(figsize=(12,20))#(x축의 길이,y축의길이)\n",
        "  #plt.imshow(file_name)\n",
        "  #plt.show()\n",
        "\n",
        "  #cv2.imwrite('/gdrive/MyDrive/tmp/new/' + name_list[len(name_list) - 1], file_name)\n",
        "  #사람만 인식된 상태로 저장 (해당 부분만 크롭은 안된 상태 - 이는 함수내에서 실행됨)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gy4GfUojCBE"
      },
      "source": [
        "##탐지 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFBf7bRRjGZx"
      },
      "outputs": [],
      "source": [
        "bboxes = model.predict(file_name2)#keras코드에서 boundary box로 bounding 됨\n",
        "\n",
        "print(len(bboxes))#갯수\n",
        "print(bboxes)#카테고리 인덱스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABZzzanBjSUF"
      },
      "outputs": [],
      "source": [
        "dummy = np.copy(file_name2)\n",
        "\n",
        "for box in bboxes:\n",
        "    \n",
        "    x1, y1, x2, y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
        "    conf = box[4]\n",
        "    cls_id = int(box[5])\n",
        "    dummy = cv2.rectangle(dummy, (x1,y1), (x2,y2), (255,0,0), 2)#빨간색, 선의 두께는 2\n",
        "plt.figure(figsize=(12,20))#(그래프 가로, 세로)\n",
        "plt.gca().set_title(\"yolov3\") # get current figure 현재의 figure를 확인하기 위한 방법 /입력한 제목 추가 \n",
        "#Axes반환한다(실제 이미지데이터의 역할)\n",
        "plt.imshow(dummy)#원하는 사이즈의 픽셀을 원하는 색으로 채워서 만든 그림 \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2mTJRdn8T1R"
      },
      "source": [
        "##hights scale value res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Suyl9W4iaDtF"
      },
      "source": [
        "##박스 네이밍\n",
        "사람 이미지만 나오도록 유도하기\n",
        "##사람 이미지만 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x14mLfETaLpU"
      },
      "outputs": [],
      "source": [
        "import core\n",
        "import colorsys\n",
        "import random\n",
        "\n",
        "def draw_bbox(file_name1, bboxes, show_label=True):\n",
        "    \"\"\"\n",
        "    bboxes: [x_min, y_min, x_max, y_max, probability, cls_id] format coordinates.\n",
        "    \"\"\"\n",
        "    Msc=[0]\n",
        "    #classes : 딕셔너리 가능 항목 가져옴 num:str\n",
        "    try:\n",
        "        classes = class_names\n",
        "    except NameError:\n",
        "        classes = core.utils.read_class_names(\"./data/classes/coco.names\")\n",
        "    num_classes = len(classes)\n",
        "    image_h, image_w, _ = file_name1.shape#이미지 크기\n",
        "\n",
        "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
        "\n",
        "    random.seed(0)\n",
        "    random.shuffle(colors)\n",
        "    random.seed(None)\n",
        "\n",
        "    for i, bbox in enumerate(bboxes):#indexing(count, list v)\n",
        "        coor = np.array(bbox[:4], dtype=np.int32)\n",
        "        \n",
        "        fontScale = 0.5\n",
        "        score = bbox[4]\n",
        "        Msc=np.append(Msc,score)\n",
        "        class_ind = int(bbox[5])\n",
        "     \n",
        "        # if :\n",
        "        #     bbox_mess = '%s: %.2f' % (classes[class_ind], score)\n",
        "        #     t_size = cv2.getTextSize(bbox_mess, 0, fontScale, thickness=bbox_thick//2)[0]\n",
        "        #     cv2.rectangle(image, c1, (c1[0] + t_size[0], c1[1] - t_size[1] - 3), bbox_color, -1)  # filled#labeling2\n",
        "\n",
        "        #     cv2.putText(image, bbox_mess, (c1[0], c1[1]-2), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        #                 fontScale, (0, 0, 0), bbox_thick//2, lineType=cv2.LINE_AA)#labeling2\n",
        "        \n",
        "        # if show_label :\n",
        "        #     bbox_mess = '%s: %.2f' % (classes[class_ind], score)\n",
        "        #     print(\"TESt\")\n",
        "        #     t_size = cv2.getTextSize(bbox_mess, 0, fontScale, thickness=bbox_thick//2)[0]\n",
        "        #     cv2.rectangle(file_name1, c1, (c1[0] + t_size[0], c1[1] - t_size[1] - 3), bbox_color, -1)  # filled#labeling2\n",
        "        #     cv2.putText(file_name1, bbox_mess, (c1[0], c1[1]-2), cv2.FONT_HERSHEY_SIMPLEX,fontScale, (0, 0, 0), bbox_thick//2, lineType=cv2.LINE_AA)#labeling2\n",
        "        print(\"BOL\",classes[class_ind])\n",
        "        if classes[class_ind] in \"person\" :\n",
        "          if score>=np.max(Msc):\n",
        "            bbox_color = colors[class_ind]\n",
        "            bbox_thick = int(0.6 * (image_h + image_w) / 600)\n",
        "            c1, c2 = (coor[0], coor[1]), (coor[2], coor[3]) \n",
        "            cv2.rectangle(file_name1, c1, c2, bbox_color, bbox_thick)\n",
        "            score=np.max(Msc)\n",
        "            print('%s'%classes[class_ind],\"SC\",score)\n",
        "            bbox_mess = '%s: %.2f' % (classes[class_ind], score)#출력되는 text\n",
        "            t_size = cv2.getTextSize(bbox_mess, 0, fontScale, thickness=bbox_thick//2)[0]\n",
        "            cv2.rectangle(file_name1, c1, (c1[0] + t_size[0], c1[1] - t_size[1] - 3), bbox_color, -1)  # filled#labeling2\n",
        "            #이미지 파일,시작점(x,y),종료점(x,y)\n",
        "\n",
        "            c1_1= (c1[0] + t_size[0], c1[1] - t_size[1] - 3)\n",
        "            #이미지 추출은 y:y+h, x:x+w로 주어준다.\n",
        "\n",
        "            ####PP=file_name1[c1[1]:c1_1[1],c1[0]:c1_1[0]]#+x값>,-y값(위 아래)<#y맞음\n",
        "            #print(\"x/y\",c1_1[1]-c1[1],\"/\",c1[0]-c1_1[0])#높이, 너비 -\n",
        "            PP=file_name1[c1[1]:c2[1],c1[0]:c2[0]]\n",
        "            cv2.imwrite(\"/gdrive/MyDrive/tmp/tester.jpg\",PP)# 사람 부분만 이미지 추출\n",
        "            ####print(c1[0],c1_1[0],\"//\",c1[1],c1_1[1])#376 476 // 0 -13\n",
        "            \n",
        "            cv2.putText(file_name1, bbox_mess, (c1[0], c1[1]-2), cv2.FONT_HERSHEY_SIMPLEX,fontScale, (0, 0, 0), bbox_thick//2, lineType=cv2.LINE_AA)#labeling2\n",
        "    #print(\"Msc\",Msc,\"//\",max(Msc)) #Msc [0.98066556 0.9436748  0.41189495 0.26212615] // 0.9806655645370483\n",
        "\n",
        "    return file_name1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN2pcR6CaP14"
      },
      "outputs": [],
      "source": [
        "file_name1 = draw_bbox(file_name2, bboxes)\n",
        "plt.figure(figsize=(12,20))#(x축의 길이,y축의길이)\n",
        "plt.imshow(file_name1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcLG5HTNNm2K"
      },
      "source": [
        "#Open Pose 사용 코드 템플릿\n",
        "##이는 이미지 처리한 것을 이용해 본다.(콕표)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YaWTc-iIIud"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/dhrim/Open-Pose-Keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqESKEa1uDDz"
      },
      "outputs": [],
      "source": [
        "%cd Open-Pose-Keras\n",
        "!pip install configobj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V56I7g-enm7k"
      },
      "source": [
        "### 데이터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46z42uEfOQSM"
      },
      "outputs": [],
      "source": [
        "!cp /gdrive/MyDrive/PROJECT/DATA/5/good/2/*.jpg ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVN5oqabOUFl"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zai5MR5-7LUq"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_odvjZ2OcTR"
      },
      "source": [
        "##모델 로딩 / 포즈 추출 시행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzpM9OYAObA5"
      },
      "outputs": [],
      "source": [
        "from open_pose_wrapper import OpenPoseWrapper\n",
        "model = OpenPoseWrapper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdRHlzSLOi-x"
      },
      "outputs": [],
      "source": [
        "file_name1 = '44.jpg'\n",
        "all_peaks1, subset1, candidate1 = model.extract(file_name1)\n",
        "model.draw_result(file_name1,all_peaks1, subset1, candidate1, draw_dot=True, draw_line=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TECv7CsAvjSm"
      },
      "outputs": [],
      "source": [
        "file_name2 = '23.jpg'\n",
        "all_peaks2, subset2, candidate2 = model.extract(file_name2)\n",
        "model.draw_result(file_name2,all_peaks2, subset2, candidate2, draw_dot=True, draw_line=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEgqaLCbPKa9"
      },
      "source": [
        "##추출 결과 / all_peak와 subset에 그 결과가 담긴다.\n",
        "- all_peaks : 추출된 모든 포인트의 정보[18개]\n",
        "- subset : 사람 별로 추출된 포인트의 정보[19개]\n",
        "\n",
        "18개 부위를 추출한다.\n",
        "각 부위의 이름은 config.py에 정의되어 있다.\n",
        "```\n",
        "part_str = [nose, neck, Rsho, Relb, Rwri, Lsho, Lelb, Lwri, Rhip, Rkne, Rank, Lhip, Lkne, Lank, Leye, Reye, Lear, Rear, pt19]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHmOer_aPK02"
      },
      "outputs": [],
      "source": [
        "#about allpeak\n",
        "import config_reader\n",
        "\n",
        "_, model_params = config_reader.config_reader()\n",
        "part_str = model_params['part_str']\n",
        "for i in range(18):\n",
        "  print(part_str[i], \": \", all_peaks1[i])#  x    y   score    point_id\n",
        "  print(part_str[i], \": \", all_peaks2[i])#  x    y   score    point_id\n",
        "all_peaks=[]\n",
        "all_peaks.append(all_peaks1)\n",
        "all_peaks.append(all_peaks2)\n",
        "\n",
        "# print(\"\\n\",all_peaks1,\"\\n\")\n",
        "# print(all_peaks2,\"\\n\")\n",
        "\n",
        "print(all_peaks)\n",
        "print(len(all_peaks))\n",
        "\n",
        "# print(all_peaks[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMKVsCtJCWAd"
      },
      "source": [
        "https://vg-rlo.tistory.com/73"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p691VISB6Ve"
      },
      "source": [
        "각 앵글의 값과 이에 대응하는 값을 처리함\n",
        "/정수 : , 실수 : score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir-gpqXErZKA"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "file_name2 = '23.jpg'\n",
        "all_peaks2, subset2, candidate2 = model.extract(file_name2)\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#print(len(all_peaks))\n",
        "\n",
        "def flatten(lst):\n",
        "    frs=[]\n",
        "    for j in range(2):#한번에 처리하기 위해 동시에 시행\n",
        "      result= []\n",
        "      print(\"jv\",j)\n",
        "      for i in range(18):\n",
        "          item = [];rs=0\n",
        "          if(len(all_peaks[j][i])==0):\n",
        "            item.append(i)#지정이 안될 경우\n",
        "            item.append(0)\n",
        "            rs=float(i)\n",
        "          else:\n",
        "            rs=(i+all_peaks[j][i][0][2])#'%07.5f'%\n",
        "          result.append(rs)\n",
        "      print(\"R\",result)\n",
        "      frs.append(result)\n",
        "    return frs\n",
        "\n",
        "peaks=flatten(all_peaks)#2차원으로 데이터입력됨(정확도)\n",
        "#peaks=np.array(peaks,dtype=float)\n",
        "#np.set_printoptions(formatter={'float_kind': lambda x: \"{0:0.5f}\".format(x)})#formatting용\n",
        "##print(\"peaks\",peaks[1])\n",
        "##print(len(peaks))\n",
        "\n",
        "# fpeaks=[]\n",
        "# for i in range(18):\n",
        "#   ans=0.0\n",
        "#   #실수 파싱\n",
        "#   if peaks[i]>=0 and peaks[i]<1:\n",
        "#     fpeaks.append(peaks[i])\n",
        "#   else:\n",
        "#     ans=peaks[i]-int(peaks[i])\n",
        "#     fpeaks.append(ans)\n",
        "# fpeaks=np.array(fpeaks,dtype=float)#float\n",
        "# print(fpeaks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2cu1rfyQDRF"
      },
      "outputs": [],
      "source": [
        "#about subset\n",
        "##print(subset1)\n",
        "#print(\"1/\",subset[0])\n",
        "#print(\"2/\",len(subset[0]))#20\n",
        "#print(\"3/\",subset[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TE9aA3uQvfa"
      },
      "source": [
        "###각 포인트별 연결 가능 여부는 limSeq에 담겨 있다\n",
        "'''\n",
        "1: nose\n",
        "2: neck\n",
        "3: Rsho\n",
        "4: Relb\n",
        "5: Rwri\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyrvyZF7QeMK"
      },
      "outputs": [],
      "source": [
        "# from open_pose_wrapper import limbSeq\n",
        "\n",
        "# print(len(limbSeq))\n",
        "# print(limbSeq)\n",
        "\n",
        "print(\"peaks\",peaks[0])\n",
        "print(\"peaks2\",peaks[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dHtASxecd3V"
      },
      "source": [
        "#CallBack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlcCjGYMcpsA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers, Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.callbacks import Callback,ModelCheckpoint\n",
        "\n",
        "import time\n",
        "\n",
        "model = Sequential([tf.keras.layers.Dense(1, input_shape=[1])])\n",
        "model.add(Input(2))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(2, activation=\"softmax\"))\n",
        "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy')\n",
        "\"\"\"\n",
        "model_check_point = ModelCheckpoint(\n",
        "    'best_model.h5', \n",
        "    monitor='val_loss', \n",
        "    verbose=1, \n",
        "    save_best_only=True)\n",
        "history = model.fit(train_x, train_y, epochs=300, batch_size=128, verbose=0, validation_split=0.2,\n",
        "                         callbacks=[model_check_point])\n",
        "\"\"\"\n",
        "\n",
        "model_check_point = ModelCheckpoint(\n",
        "    'best_model.h5', \n",
        "    monitor='loss', \n",
        "    verbose=1, \n",
        "    save_best_only=True)\n",
        "\n",
        "#history = model.fit(np.array([all_peaks[0][0][0],all_peaks[0][0][1]]),subset[0], epochs=10, batch_size=128, verbose=0,callbacks=[model_check_point])\n",
        "history = model.fit(peaks[0],peaks[1], epochs=10, batch_size=18, verbose=1,callbacks=[model_check_point])\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "#plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pAREm8Pm6RA"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "\n",
        "output.clear()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GYM_v2_5_20220826.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}