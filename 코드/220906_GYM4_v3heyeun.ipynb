{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZEw4XqL4VuD"
      },
      "source": [
        "#드라이브 바운드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eS2Xp_QB03PO"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymwPZmqtkwWd"
      },
      "outputs": [],
      "source": [
        "#cd STAND1500\n",
        "#cd TRAIN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2_S78dA208M"
      },
      "source": [
        "#DATA 작 해주기 - train/test/validation\n",
        "\n",
        "\n",
        "```\n",
        "1. split folder ratio 사용\n",
        "!pip install split-folders\n",
        "import splitfolders\n",
        "\n",
        "#splitfolders.ratio('인풋경로',output='output경로' ,seed=77, ratio= (0.8,0.1,0.1)) \n",
        "#처음폴더를 output foloder(없다면 생성해준후 실행)로 train-valid-test 데이터를 0.8,0.1,0.1의 비율로 나눠줘\n",
        "\n",
        "# splitfolders.ratio('/content/drive/MyDrive/tmp/pose_estimiation/bad',)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaYhZPZkVWgC"
      },
      "source": [
        "#YOLO를 인식"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV8SMXRAVaMO"
      },
      "outputs": [],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efHIM12lVg3V"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/dhrim/darkeras-yolov4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L12zKlHSVn4K"
      },
      "outputs": [],
      "source": [
        "%cd darkeras-yolov4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVKmdV4ZVpJQ"
      },
      "outputs": [],
      "source": [
        "!wget -O weights/yolov3.weights https://pjreddie.com/media/files/yolov3.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOyW9uBoVslB"
      },
      "source": [
        "##모델 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCi3HPGCVvjp"
      },
      "outputs": [],
      "source": [
        "import yolov3_wrapper\n",
        "model = yolov3_wrapper.YoloV3Wrapper(\"weights/yolov3.weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9R_Dq1T9VxKW"
      },
      "outputs": [],
      "source": [
        "model.save(\"yolov3.h5\")#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4Kd-_pIZEV_"
      },
      "source": [
        "##이미지 로딩 \n",
        "- 이는 sit, stand를 따로 진행한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAA1H2UTY6u4"
      },
      "outputs": [],
      "source": [
        "#폴더의 모든 사진을 불러옴 - 확인용 코드(안돌려도 됨)\n",
        "import glob\n",
        "\n",
        "for filename in glob.glob('/gdrive/MyDrive/PROJECT/DATA0829/SIT1500/*/*.jpg'):\n",
        "  #print(filename)\n",
        "  name_list = filename.split(\"/\")\n",
        "  #print(name_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqXVYM0QVO3-"
      },
      "source": [
        "#OpenPose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWhIwqKGZVFs"
      },
      "source": [
        "##프로젝트 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYPOtsCtZUkk"
      },
      "outputs": [],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTQ8-mkkVOLX"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/dhrim/Open-Pose-Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cMtaCm2ZfSh"
      },
      "outputs": [],
      "source": [
        "%cd Open-Pose-Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqWJXqgyZigN"
      },
      "source": [
        "##install library & 모델 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJnm6I4DZlv5"
      },
      "outputs": [],
      "source": [
        "!pip install configobj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st6wlaQYZu3g"
      },
      "outputs": [],
      "source": [
        "from open_pose_wrapper import OpenPoseWrapper\n",
        "model = OpenPoseWrapper()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaDReQqzZ1Go"
      },
      "source": [
        "##pose detect\n",
        "- https://cmu-perceptual-computing-lab.github.io/openpose/web/html/doc/md_doc_03_python_api.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQnEzvEejIhq"
      },
      "outputs": [],
      "source": [
        "%cd /content/Open-Pose-Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqcJWyJpZ1fU"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "#기존 예시 코드\n",
        "file_name = \"yuna.jpg\"\n",
        "all_peaks, subset, candidate = model.extract(file_name)\n",
        "model.draw_result(file_name, all_peaks, subset, candidate, draw_dot=True, draw_line=True)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdUa0_w5fB-D"
      },
      "source": [
        "from open_pose_wrapper import OpenPoseWrapper\n",
        "이 부분을 시행 해주어야 error안난다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL39xKGrO5Bk"
      },
      "source": [
        "#Get angle  vlaue_ori\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVXtbUNmZ9yP"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import config_reader\n",
        "import math\n",
        "from IPython.display import Image, display\n",
        "from google.colab import output\n",
        "\n",
        "#directory address\n",
        "dad='/gdrive/MyDrive/PROJECT/DATA0829/SIT1500/TRAIN/*/*.jpg'\n",
        "\n",
        "#for file_name in glob.glob('/gdrive/MyDrive/DATA0829/STAND1500/TRAIN/GOOD/IMG_0643.jpg'):\n",
        "#for file_name in glob.glob('/gdrive/MyDrive/DATA0829/STAND1500/TRAIN/BAD4/IMG_9988.jpg'):\n",
        "#for file_name in glob.glob('/gdrive/MyDrive/DATA0829/SIT1500/TEST/BAD1/20220817_190933_039.jpg'): #연습용 사진\n",
        "for file_name in glob.glob('/gdrive/MyDrive/PROJECT/DATA0829/SIT1500/TRAIN/*/*.jpg'): #원하는 디렉토리 경로로 변경\n",
        "  all_peaks,subset,candidate = model.extract(file_name)\n",
        "  model.draw_result(file_name, all_peaks, subset, candidate, draw_dot=True, draw_line=True)\n",
        "\n",
        "  #2\n",
        "  model.extract_and_draw(file_name)\n",
        "\n",
        "  #3\n",
        "  #part_str = [nose, neck, Rsho, Relb, Rwri, Lsho, Lelb, Lwri, Rhip, Rkne, Rank, Lhip, Lkne, Lank, Leye, Reye, Lear, Rear, pt19]\n",
        "  _, model_params = config_reader.config_reader()\n",
        "  part_str = model_params['part_str']\n",
        "  #print(len(all_peaks))\n",
        "\n",
        "  #4\n",
        "  #Relb가 없으면 왼쪽을 바라 본 사진임으로 Relb 유무로 사진의 좌우를 판별\n",
        "  if not all_peaks[3]: #Relb가 없는 경우 - 왼쪽을 바라본 사진\n",
        "    if not all_peaks[-2]:\n",
        "      all_peaks[-2] = all_peaks[-1]\n",
        "\n",
        "    neck_angle = math.degrees(math.atan2(all_peaks[5][0][1] - all_peaks[-2][0][1], all_peaks[5][0][0] - all_peaks[-2][0][0])) #어깨 - 귀\n",
        "    spine_angle = math.degrees(math.atan2(all_peaks[12][0][1] - all_peaks[11][0][1], all_peaks[12][0][0] - all_peaks[11][0][0])) #무릎 - 엉덩이\n",
        "  else: \n",
        "    if not all_peaks[-1]:\n",
        "      all_peaks[-1] = all_peaks[-2]\n",
        "\n",
        "    neck_angle = abs(math.degrees(math.atan2(all_peaks[-1][0][1] - all_peaks[2][0][1], all_peaks[-1][0][0] - all_peaks[2][0][0]))) #귀 - 어깨\n",
        "    spine_angle = math.degrees(math.atan2(all_peaks[9][0][1] - all_peaks[8][0][1], all_peaks[9][0][0] - all_peaks[8][0][0]))\n",
        "\n",
        "  print(f\"angle: neck_angle = {neck_angle}, spine_angle = {spine_angle}\")\n",
        "\n",
        "  #5\n",
        "  #10을 빼고 반올림\n",
        "  neck_angle = round(neck_angle / 10)\n",
        "  spine_angle = round(spine_angle / 10)\n",
        "\n",
        "  print(f\"label: neck_angle = {neck_angle}, spine_angle = {spine_angle}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBKU3O1WvKUV"
      },
      "source": [
        "###Get angle  vlaue_데이터 저장 수행 함수 이용법\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sg2v6RsAvKrd"
      },
      "outputs": [],
      "source": [
        "# #확인용\n",
        "# %%writefile /gdrive/MyDrive/PROJECT/OTHER/filen.csv\n",
        "# num1\"/\"test, alpha, the_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaVOjdyZw7Do"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMnfvcyqE5sg"
      },
      "source": [
        "##Get angle  vlaue_save.csv (09/05)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-mKFU0eZKQP"
      },
      "outputs": [],
      "source": [
        "  #6_save   /  x, y, NA, SA, class1, class2 #file 초기화 작업도 가능\n",
        "  %%writefile /gdrive/MyDrive/PROJECT/DATA0829/tmp_data/stand0906.csv\n",
        "  XYsh,mXYear,XYkn,XYbt,NA,SA,clasf1,clasf2,clasf3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QfwxujzbY6r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "cv_ad='/gdrive/MyDrive/PROJECT/DATA0829/tmp_data/stand0906.csv'\n",
        "tmp_dict=pd.read_csv (cv_ad)\n",
        "tmp_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV5gSuc1ZgvB"
      },
      "source": [
        "```\n",
        "https://www.geeksforgeeks.org/how-to-append-pandas-dataframe-to-existing-csv-file/\n",
        "``` --> we can write the dataframe to the CSV file in append mode by the parameter a using the pandas to_csv() function.\n",
        "적용은 작업완료후 되는듯?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-XWVfYmxLWJ"
      },
      "source": [
        "추출된 점이 담긴 all_peaks는 18개의 요소가 있는 리스트이다.\n",
        "- part_str[#] :신체부위 text\n",
        "- all_peaks[1#][2#][3#] :\n",
        "    - [1#] : the people tuple data to list // 즉 한 신체부위의 값이다. 다수의 사람에 대해\n",
        "```\n",
        "(484, 130, 0.7376982569694519, 1)\n",
        "  x    y   score               point_id\n",
        "```\n",
        "    - [2#] : one person data\n",
        "    - [3#] : 한 사람의 데이터에서 특정 데이터 추출\n",
        "- 18 parts\n",
        "```\n",
        "part_str = [nose, neck, Rsho, Relb, Rwri, Lsho, Lelb, Lwri, Rhip, Rkne, Rank, Lhip, Lkne, Lank, Leye, Reye, Lear, Rear, pt19]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf9xBOQKamfi"
      },
      "source": [
        "##train sit에 대해서만(전반적으로 이용가능하게 수정 필요./반복을 가능한 줄이자)\n",
        "- 저장하는 부분\n",
        "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html\n",
        "-임의로 stand부분을 학습 시켰는데\n",
        "```\n",
        "FILE_NAME /gdrive/MyDrive/PROJECT/DATA0829/STAND1500/TRAIN/GOOD/20220819_153418_025_saved.jpg\n",
        "['', 'gdrive', 'MyDrive', 'PROJECT', 'DATA0829', 'STAND1500', 'TRAIN', 'GOOD', '20220819_153418_025_saved.jpg']\n",
        "pos: STAND state: GOOD name: 20220819_153418_025_saved.jpg\n",
        "angle: neck_angle = 84.90788487550104, spine_angle = 88.5607103721176\n",
        "tmp_dict:          XYsh     XYear       XYkn       XYbt    NA    SA clasf1 clasf2  \\\n",
        "0  (92, 175)  (83, 74)  (92, 599)  (87, 400)  80.0  90.0  STAND   GOOD   \n",
        "```\n",
        "식으로 특수처리 되어야 햐는 부분조차 나오고 있다. 저장할때도 이러는지는 확실치는 않다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1mcvAYCFH_E"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import config_reader\n",
        "import math\n",
        "from IPython.display import Image, display\n",
        "from google.colab import output\n",
        "\n",
        "#directory address\n",
        "dad='/gdrive/MyDrive/PROJECT/DATA0829/STAND1500/TRAIN/*/*.jpg'\n",
        "#/gdrive/MyDrive/PROJECT/DATA0829/STAND1500/TRAIN/BAD1\n",
        "for file_name in glob.glob(dad): #원하는 디렉토리 경로로 변경\n",
        "  all_peaks,subset,candidate = model.extract(file_name)\n",
        "  model.draw_result(file_name, all_peaks, subset, candidate, draw_dot=True, draw_line=True)#\n",
        "  print(\"FILE_NAME\",file_name)\n",
        "  #get data feacture - split text -> pos,state,fname \n",
        "  d=file_name.split(\"/\")#return list\n",
        "  print(d)\n",
        "  pos=d[d.index(\"DATA0829\")+1].strip(\"1500\")\n",
        "  st=d[d.index(\"DATA0829\")+3]\n",
        "  fn=d[d.index(\"DATA0829\")+4]\n",
        "  print(\"pos:\",pos,\"state:\",st,\"name:\",fn)\n",
        "  #2\n",
        "  #model.extract_and_draw(file_name)#\n",
        "\n",
        "  #3\n",
        "  #part_str = [nose, neck, Rsho, Relb, Rwri, Lsho, Lelb, Lwri, Rhip, Rkne, Rank, Lhip, Lkne, Lank, Leye, Reye, Lear, Rear, pt19]\n",
        "  _, model_params = config_reader.config_reader()\n",
        "  part_str = model_params['part_str']\n",
        "\n",
        "  #4\n",
        "  #Relb가 없으면 왼쪽을 바라 본 사진임으로 Relb 유무로 사진의 좌우를 판별\n",
        "    #에러 처리\n",
        "  try:\n",
        "    if not all_peaks[3]: #Relb가 없는 경우 - 왼쪽을 바라본 사진\n",
        "      if not all_peaks[-2]:\n",
        "        all_peaks[-2] = all_peaks[-1]\n",
        "    #atan2(y, x) \n",
        "      neck_angle = math.degrees(math.atan2(all_peaks[5][0][1] - all_peaks[-2][0][1], all_peaks[5][0][0] - all_peaks[-2][0][0])) #어깨 - 귀\n",
        "      spine_angle = math.degrees(math.atan2(all_peaks[12][0][1] - all_peaks[11][0][1], all_peaks[12][0][0] - all_peaks[11][0][0])) #무릎 - 엉덩이\n",
        "      \n",
        "      sx,sy=all_peaks[5][0][0],all_peaks[5][0][1]\n",
        "      ex,ey= all_peaks[-2][0][0], all_peaks[-2][0][1]\n",
        "      kx,ky=all_peaks[12][0][0],all_peaks[12][0][1]\n",
        "      bx,by= all_peaks[11][0][0], all_peaks[11][0][1]\n",
        "    else: \n",
        "      if not all_peaks[-1]:\n",
        "        all_peaks[-1] = all_peaks[-2]\n",
        "      neck_angle = abs(math.degrees(math.atan2(all_peaks[-1][0][1] - all_peaks[2][0][1], all_peaks[-1][0][0] - all_peaks[2][0][0]))) #귀 - 어깨\n",
        "      spine_angle = abs(math.degrees(math.atan2(all_peaks[9][0][1] - all_peaks[8][0][1], all_peaks[9][0][0] - all_peaks[8][0][0])))\n",
        "      \n",
        "      sx,sy= all_peaks[2][0][0], all_peaks[2][0][1]\n",
        "      ex,ey=all_peaks[-1][0][0],all_peaks[-1][0][1]\n",
        "      kx,ky= all_peaks[8][0][0], all_peaks[8][0][1]\n",
        "      bx,by= all_peaks[9][0][0], all_peaks[9][0][1]\n",
        "    print(f\"angle: neck_angle = {neck_angle}, spine_angle = {spine_angle}\")\n",
        "  except IndexError:\n",
        "    print(\"Indexerror file name is....\",fn,\"\\n\")#에러 분명히 날껀데 이 구문 출력이 왜 안뜨는지...\n",
        "    continue\n",
        "  sxy=(sx,sy)\n",
        "  exy=(ex,ey)\n",
        "  kxy=(kx,ky)\n",
        "  bxy=(bx,by)\n",
        "\n",
        "  #4-1 90degree over 예외처리?맞는지 확인 필요(09/05)\n",
        "  if neck_angle>90:\n",
        "    neck_angle=neck_angle-90\n",
        "  elif spine_angle>180:\n",
        "    spine_angle=spine_angle-180\n",
        "  #5\n",
        "    #10을 빼고 반올림\n",
        "  #print('Before Round',f\"angle: neck_angle = {neck_angle}, spine_angle = {spine_angle}\")\n",
        "  neck_angle = round(neck_angle ,- 1)\n",
        "  spine_angle = round(spine_angle,- 1)\n",
        "  #6-1/ not working\n",
        "    #tmp_dict.loc[len(tmp_dict)]=[sxy,exy,kxy,bxy,neck_angle,spine_angle,None,None]\n",
        "  #6-2\n",
        "  dt={ \"XYsh\":[sxy],\"XYear\":[exy],\"XYkn\":[kxy],\"XYbt\":[bxy],\"NA\":[str(neck_angle)],\"SA\":[str(spine_angle)],\n",
        "       \"clasf1\":[pos],\"clasf2\":[st],\"clasf3\":[fn] }\n",
        "  tmp_dict=pd.DataFrame(dt)\n",
        "  tmp_dict.to_csv(cv_ad,mode='a',index=False,header=False)\n",
        "  print(\"tmp_dict: \",tmp_dict)\n",
        "  #print(\"FINAL\",f\"label: neck_angle = {neck_angle}, spine_angle = {spine_angle}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t87zcE6rbGFZ"
      },
      "source": [
        "##파일 출력하는 기능[csv]\n",
        "- tmp (9/6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxzMaY3ZbNXi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "#directory address\n",
        "#dad='/gdrive/MyDrive/PROJECT/DATA0829/SIT1500/TRAIN/*/*.jpg'\n",
        "\n",
        "for file_name in glob.glob(cv_ad):\n",
        "  with open(file_name, newline='', encoding='utf-8') as f:\n",
        "      reader = csv.reader(f)#to_csv로 바꾸기\n",
        "      for row in reader:\n",
        "          print(row)#저장을 해야할까 바로 불러서 쓰는 방식을 이용해야 하는지 고민해야 할것 같다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnlQEnFRqhAK"
      },
      "source": [
        "##확인용?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2fZI0pEaNV6"
      },
      "outputs": [],
      "source": [
        "import config_reader\n",
        "\n",
        "_, model_params = config_reader.config_reader()\n",
        "part_str = model_params['part_str']\n",
        "for i in range(18):\n",
        "  print(part_str[i], \": \", all_peaks[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cVDjeCEaWqA"
      },
      "outputs": [],
      "source": [
        "#기존 예시 코드 - 실행 x\n",
        "model.extract_and_draw(file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdOGxMg7aan7"
      },
      "source": [
        "###all peaks print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4t3V9SEaeSE"
      },
      "outputs": [],
      "source": [
        "print(len(all_peaks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boygmKC6agUA"
      },
      "outputs": [],
      "source": [
        "import config_reader\n",
        "\n",
        "_, model_params = config_reader.config_reader()\n",
        "part_str = model_params['part_str']\n",
        "for i in range(18):\n",
        "  print(part_str[i], \": \", all_peaks[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiv9ZYIbakk9"
      },
      "source": [
        "\n",
        "- 1개의 point는 다음과 같이 구성된다.\n",
        "```\n",
        "(484, 130, 0.7376982569694519, 1)\n",
        "  x    y   score               point_id\n",
        "```\n",
        "- point_id는 all_peaks에 명시되어 있다.\n",
        "\n",
        "```\n",
        "all_peaks의 내용\n",
        "\n",
        "(177, 6, 0.11634597013471648, 0)\n",
        "(484, 130, 0.7376982569694519, 1)\n",
        "(287, 154, 0.9168482273817062, 2)\n",
        "(410, 221, 0.9359188675880432, 3)\n",
        "\n",
        "각 줄의 마지막 숫자가 point_id이다.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joTx4Cnbam3s"
      },
      "source": [
        "subset의 경우 이미지에서 한 사람의 값을 가진다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJRv80HEa65I"
      },
      "source": [
        "각 포인트별 연결 가능 여부는 limSeq에 담겨 있다.\n",
        "\n",
        "\n",
        "\n",
        "[2, 3] 은 neck과 Rsho(righst shoulder)가 연결되어 있음을 의미하고, \n",
        "\n",
        "[3,4]는 Rsho(righst shoulder)와 Relb(right elbow)가 이어져 있다는 것을 의미한다.\n",
        "\n",
        "```\n",
        "1: nose\n",
        "2: neck\n",
        "3: Rsho\n",
        "4: Relb\n",
        "5: Rwri\n",
        "...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtChU3CVO9c6"
      },
      "source": [
        "#Save&Load .csv file data\n",
        "\n",
        "\n",
        "```\n",
        "x, y, NA, SA, class1, class2\n",
        "\n",
        "```\n",
        "- if the vlaue not exist- > 0 or None\n",
        "-  참고자료 \n",
        "https://colab.research.google.com/github/datascienceschool/book/blob/master/ds/01%20python/04.02%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%9E%85%EC%B6%9C%EB%A0%A5.ipynb#scrollTo=ZQxwXT9GP-4A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyrJ8t0VQ9_E"
      },
      "source": [
        "`%%writefile` 매직(magic) 명령으로 만들어보자. 이 명령은 셀에 서술한 내용대로 텍스트 파일을 만드는 명령이다.\n",
        "```\n",
        "%%writefile STAND_TRAIN.csv\n",
        "x, y, NA, SA, class1, class2\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJFRG75MRVvP"
      },
      "source": [
        "## CSV파일로부터 데이터를 읽어 데이터 프레임을 만들 때\n",
        "- CSV 파일로부터 데이터를 읽어 데이터프레임을 만들 때는 `pandas.read_csv` 함수를 사용한다. 함수의 입력값으로 파일 이름을 넣는다.\n",
        "- 확장자가 CSV가 아닌 파일 즉, 데이터를 구분하는 구분자(separator)가 쉼표(comma)가 아니면 `sep` 인수를 써서 구분자를 사용자가 지정해준다. 만약 길이가 정해지지 않은 공백이 구분자인 경우에는 `\\s+` 정규식(regular expression) 문자열을 사용한다.\n",
        "- 만약 자료 파일 중에 건너 뛰어야 할 행이 있으면 ```skiprows ```인수를 read_csv함수에 적용하여 이용\n",
        "- 특정한 값을 NaN으로 취급하고 싶으면 `na_values` 인수에 NaN 값으로 취급할 값을 넣는다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnXqPLlsRJyj"
      },
      "outputs": [],
      "source": [
        "pd.read_csv('STAND_TRAIN.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlPHb-aJT_KD"
      },
      "outputs": [],
      "source": [
        "#pd.read_table('STAND_TRAIN.txt', sep='\\s+')#pd.read_csv('sample4.txt', skiprows=[0, 1])\n",
        "#df = pd.read_csv('sample5.csv', na_values=['누락'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA8JXLycUnB-"
      },
      "source": [
        "##CSV파일 출력\n",
        "- `to_csv` 메서드를 사용한다.(cat과 비슷하게 인자를 추가해서 이용이 가능)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icPgphWcyd2u"
      },
      "source": [
        "#Vanilla CNN Template\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3g9RX2BS7oV"
      },
      "source": [
        "##모듈임포팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PjQAtOCyco0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import GaussianNoise\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, BatchNormalization, Conv2D, MaxPooling2D, Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "import time\n",
        "\n",
        "from tensorflow.keras.applications import efficientnet\n",
        "from tensorflow.keras.applications import EfficientNetB2\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcX4sUfDS4o9"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Input((224,224,3)))\n",
        "model.add(GaussianNoise(0.1))\n",
        "model.add(Conv2D(64, (3,3), padding='same'))\n",
        "model.add(Conv2D(64, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(128, (3,3), padding='same'))\n",
        "model.add(Conv2D(128, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(256, (3,3), padding='same'))\n",
        "model.add(Conv2D(256, (3,3), padding='same'))\n",
        "model.add(Conv2D(256, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq3wSN5LwWth"
      },
      "outputs": [],
      "source": [
        "#다중분류\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"Adam\", metrics=['acc'])\n",
        "#good,bad만 분류하면되니까 2진분류\n",
        "# model.compile(loss='binary_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "def normalize(image):\n",
        "  return image/255.0\n",
        "\n",
        "preprocessor = normalize\n",
        "BATCH_SIZE = 64 # BATCH_SIZE = 128\n",
        "\n",
        "train_data_generator = ImageDataGenerator(#이미지 augmentation(증가) / return v - 입력이 변형된 상태\n",
        "      rotation_range=5, #bad1~4,good 5개\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=False,\n",
        "      preprocessing_function=preprocessor\n",
        ").flow_from_directory(#이미지가 저장된 폴더를 기준으로 라벨 정보와 함께 이미지를 불러들임\n",
        "      \"/gdrive/MyDrive/PROJECT/DATA0829/STAND1500/TRAIN\",#학습시킬 경로\n",
        "      target_size=(224,224),#이미지 크기 fix - 넘어가게 되면 그래픽 에러 남\n",
        "      batch_size=BATCH_SIZE,\n",
        "      class_mode='sparse'\n",
        ")\n",
        "\n",
        "test_data_generator = ImageDataGenerator(\n",
        "      preprocessing_function=preprocessor#이미지 처리전에 주어진 값을곱해 크기를 조정.    \n",
        ").flow_from_directory(\n",
        "      \"/gdrive/MyDrive/PROJECT/DATA0829/STAND1500/TEST\", #test경로\n",
        "      target_size=(224,224),\n",
        "      batch_size=BATCH_SIZE,\n",
        "      class_mode='sparse'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHDruxJ7wwwC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "model_check_point = ModelCheckpoint(\n",
        "    'pose_best_model.h5', \n",
        "    monitor='val_loss', \n",
        "    verbose=1, \n",
        "    save_best_only=True)\n",
        "#모델체크포인트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TIWmkkG27Vz"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "      train_data_generator,\n",
        "      validation_data=test_data_generator,\n",
        "      steps_per_epoch=train_data_generator.samples/BATCH_SIZE,\n",
        "      validation_steps=test_data_generator.samples/BATCH_SIZE,      \n",
        "      epochs=100, callbacks=[model_check_point]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKcUQN2KSsEp"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('pose_best_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIvMXsI6bUz-"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(\n",
        "      test_data_generator,\n",
        "      steps=test_data_generator.samples/BATCH_SIZE\n",
        ")\n",
        "print(\"loss=\", loss)\n",
        "print(\"acc=\", acc)\n",
        "\n",
        "\n",
        "\n",
        "test_x, test_y = next(iter(test_data_generator))\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=-1)\n",
        "\n",
        "plt.plot(test_y[:100], \"o\")\n",
        "plt.plot(predicted[:100], '.')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7d9neMj38kA"
      },
      "source": [
        "https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/tutorials/keras/save_and_load.ipynb?hl=ko\n",
        "\n",
        "참고 사이트"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "GBKU3O1WvKUV"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}