9/3일 토요일 오프라인 멘토링

멘토링 내용

1. 각도를 학습을 어떻게 시켜야 하는지 (현재 딕셔너리로 저장되는 방식 생각중)
- 각도의 숫자를 스칼라값 그대로 입력으로 하고, 0-90까지 있는 카테고리를 생각하지 않고 분류식으로 접근하기
- 숫자 값을 출력하는 회귀로 생각해보기
- 카테고리하는게 장점이 없으니까 0-90개의 카테고리가 아니라 숫자 자체를 출력하게 해야함
- 카테고리를 하게 되면 각도의 데이터를 일일히 구해야한다 0도 몇십장, 1도 몇십장, 이렇게 가야하기 때문에
- 각도를 입력으로 사용하는 피처값 하나로 생각한다
- 입력은 피처값만 넣고 (사과 무게로 생각하기. 사과 무게를 각도값으로 익었다, 안익었다가 거북목, 거북목이아니다)
- 계산(0-50까진 거북목이아님) 해서 값을 무게고 색깔(목각도, 허리각도)같은 다른 피처로 입력받으면 된다
- 인식이 잘못되어 90이 넘어가면 Normalization 시켜주면 관계없을것 같다
- 각도도 Normalization 시켜줄 수 있음.


2. 딕셔너리로 값을 지정해서 추출하려 했는데, csv로 저장해서 학습 시킨 후에 모델을 저장해놓고 바로 하는게 좋은지
- pickle를 이용해 딕셔너리로 저장해서 읽어오든가
- csv를 저장한 후 넘파이나 판다스로 로딩해서 읽어오든가
- 로딩해서 학습을 위한 모양으로 만들때 코드 구현이 쉬운 걸로 가면 됨, 고민할 문제는 아님.


3. 오픈포즈 하고 나서 draw_result를 for문을써서 사진으로 출력하면 그때그때 결과값이 나왔으면 좋겠는데 마지막값만 나온다
- 강사님이 작성한 코드고 그렇게 나오게 만들었기 때문
- 바꾸고 싶다면 draw_result를 들어가서 코드파악해서 작성하기
- 지나가는걸 결과로 보여주고 싶은거라면 동영상 트랙킹이라는 테스트가 따로 있고
- 어필은 되지만 제대로 실행되지 않을 경우엔 오히려 독이 될 수 있음
- 차라리 draw해서 살짝씩 움직이는걸 10장정도 출력한다음에 동영상gif로 만들어 동영상에 
- 사진으로 10장 열거하는것보다 동영상으로 만드는게 어필하기 좋음


4. 현재 이미지로 sit을 학습시킨 결과가 있는데, val_acc 0.50미만이면 쓸 수 없는데 0.37같은 수치가 자주 나옴
- good하고 bad로만 나눠서 분류해보기
- bad 끼리 확 구별이 안되어서 그런것이다
- 구별이 안되는게 충분히 성능에 영향을 준다
- 자전거 자동차는 구별할 수 있지만, 예쁜 자동차와 덜예쁜 자동차는 구별하기 어려움 이걸로 생각하면 이해가 쉬울것임
- 지금 결과를 보면 val_acc랑 acc의 차이가 큰데, 이건 오버피팅으로 생각해야함
- 모델크기를 좀 줄여본다던지, augument(증가) 해보던지
- augument를 해줬다면 적은 데이터는 아닐것이다
- good하고 bad로만 해보라는 이유는 안되는거 아예 붙잡고 있기 보다는 잘되는거에서 조금씩 넓혀나가는게 더 쉽기 때문.


5. 동영상과 피피티 프로토타입 컨펌
- 결과보고서, 소스코드, 동영상만 있으면 됨
- 동영상은 1분30초
- 코드 완성된 다음에 만들기로 함.


6. 측면 사진의 경우, 왼쪽을 바라본 사진이면 왼쪽 귀만, 오른쪽을 바라본 경우는 오른쪽 귀만 인식이 되어야 하는데
왼쪽 귀를 오른쪽 귀로 인식하는 경우(왼쪽 귀만 나온 측면 사진인데도 all_peak 리스트에 LEAR값은 비어 있고 REAR 값만 존재)
이 값을 그대로 사용해도 괜찮은가요? (각도를 구하기 위해 본래는 왼쪽 귀와 왼쪽 어깨 값이 필요함) 그리고 이렇게 인식되는 이유도 알 수 있을까요?
- 촬영하는 포인트가 조금씩 달라져서 생긴 문제같고, 촬영하는 시점을 고정시키면 해결될 문제다
- 자세만 같다면 상관은 없다 그대로 써도 된다.


7. 한 사람의 측면 사진임에도 불구하고 all_peak 리스트에 특정 요소가 두 개 이상 들어가는 경우,
예를 들어 마지막 인덱스인 rear 값이 2개 이상(하나의 신체 요소에 point_id가 2개 이상) 들어가는 경우 어떤 값을 사용하는게 좋은가요?
- 탐지가 잘못되어서 두사람이 있다고 본거다
- 그런 사진만 빼자고 했는데 생각보다 개수가 많아지면 탐지된 id를 보고 다른사람으로 나오는 데이터를 없애기
- 각각 하나씩 있다가 몇개만 두개가 나올텐데 1번사람것만 쓰겠다 이런식으로 추리기
- 탐지가 안된 부분은 생략되고 다음사람걸로 되는 경우가 있는데 (귀-15번이 탐지가 안되면 그 자리를 눈-16번->15번이 차지함)
- 어차피 다 한사람거니까 candidate 서브셋 변수명을 찾아보기 (관련함수)
- 그거 사용하면 한사람으로 추릴 수 있다.

---------------------------------------------------------------

+ 회의 후 잡담 (읽으면 지움)


사실상 3D에서는 각도가 의미있을거 같지 않은게
3d에서는 보는 각도에 따라서 관점이 확확 달라지기 때문에
절대적인 각도가 3d에 xyz가 있을때 집어내는건 몰라도
openpose를 통하면 2차원 좌표밖에 못구하기 때문에 각도를 쓰면 정보가 사라질거같음

2D로 간다면 측면만 찍어야하는 제약이자 단점을 언급을 안해버려야함
2D로 간다면 각도 쓰는건 의미가 있다
의미가 없다고 한건 어디서 촬영했냐에 따라 달라지는거지만
옆에만 제한을 둔다면 의미가 있다

결과보고서, 소스코드, 동영상을 테스트 전문 업체한테 맡겨서 실제로 코드가 동작하는지 확인
설치가이드, 운영가이드 보고 따라할거니까 가져다놔야하는걸 전제하지말고 프로젝트에 샘플파일 포함시켜놓기
딥러닝을 학습시켜서 확인하진않을거고 미리 학습된 파일을 다운로드 받아서 쓰기
코드만 있고 데이터도 없고 학습도 못시킨다 그러면 안씀
모델이 커지면 깃헙에 올리기 적당하지않음 그렇다면
구글 드라이브에 올려서 쉐어해서 다운받을 수 있게 하기

---------------------------------------------------------------

다음주 월요일까지
- 회의록 보고 
